{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassnaakharboush/soft/blob/main/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItVc7NyqJYSd",
        "outputId": "c2ac70bd-940f-42f6-b4f6-2bfdd2c97e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyswarms in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from pyswarms) (25.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyswarms) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pyswarms) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
            "Dropped features: [' ROA(A) before interest and % after tax', ' ROA(B) before interest and depreciation after tax', ' Realized Sales Gross Margin', ' Pre-tax net Interest Rate', ' After-tax net Interest Rate', ' Continuous interest rate (after tax)', ' Net Value Per Share (A)', ' Net Value Per Share (C)', ' Per Share Net profit before tax (Yuan ¥)', ' Regular Net Profit Growth Rate', ' Net worth/Assets', ' Operating profit/Paid-in capital', ' Net profit before tax/Paid-in capital', ' Current Liabilities/Equity', ' Working capitcal Turnover Rate', ' Cash Flow to Sales', ' Current Liability to Liability', ' Current Liability to Equity', ' Net Income to Total Assets', ' Gross Profit to Sales', ' Liability to Equity']\n",
            "\n",
            "--- Logistic Regression (All features) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       592\n",
            "           1       0.50      0.24      0.32        34\n",
            "\n",
            "    accuracy                           0.95       626\n",
            "   macro avg       0.73      0.61      0.65       626\n",
            "weighted avg       0.93      0.95      0.94       626\n",
            "\n",
            "Accuracy: 0.9457\n",
            "Precision: 0.5000\n",
            "Recall: 0.2353\n",
            "F1 Score: 0.3200\n"
          ]
        }
      ],
      "source": [
        "!pip install pyswarms  # uncomment if pyswarms not installed\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pyswarms as ps  # for PSO\n",
        "\n",
        "# --- Load and preprocess dataset ---\n",
        "df = pd.read_csv('/content/sample_data/data.csv')  # change path if needed\n",
        "\n",
        "# Drop highly correlated features (threshold 0.9)\n",
        "corr_matrix = df.drop('Bankrupt?', axis=1).corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [col for col in upper.columns if any(upper[col] > 0.9)]\n",
        "df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "print(f\"Dropped features: {to_drop}\")\n",
        "\n",
        "X = df.drop('Bankrupt?', axis=1).values\n",
        "y = df['Bankrupt?'].values\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Bankrupt?', axis=1)\n",
        "y = df['Bankrupt?']\n",
        "\n",
        "# Handle missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)  # Now X is a NumPy array with no NaNs\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# -------------------------\n",
        "# 1) ML baseline: Logistic Regression with all features\n",
        "# -------------------------\n",
        "model_ml = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_ml.fit(X_train, y_train)\n",
        "y_pred_ml = model_ml.predict(X_test)\n",
        "\n",
        "# Metrics function\n",
        "def print_metrics(y_true, y_pred, title=\"\"):\n",
        "    print(f\"\\n--- {title} ---\")\n",
        "    print(classification_report(y_true, y_pred, zero_division=0))\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "\n",
        "print_metrics(y_test, y_pred_ml, \"Logistic Regression (All features)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.base import clone\n",
        "import random\n",
        "\n",
        "def fitness_function(chromosome, X_train, y_train):\n",
        "    if sum(chromosome) == 0:\n",
        "        return 0\n",
        "    X_subset = X_train[:, chromosome==1]\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    scores = cross_val_score(model, X_subset, y_train, cv=3, scoring='accuracy')\n",
        "    return scores.mean()\n",
        "\n",
        "def run_ga_feature_selection(X_train, y_train, n_pop=20, n_gen=10, mutation_rate=0.1):\n",
        "    n_features = X_train.shape[1]\n",
        "    population = [np.random.randint(0,2,n_features) for _ in range(n_pop)]\n",
        "\n",
        "    best_chromosome = None\n",
        "    best_fitness = 0\n",
        "\n",
        "    for gen in range(n_gen):\n",
        "        fitness_scores = np.array([fitness_function(ind, X_train, y_train) for ind in population])\n",
        "\n",
        "        # Select best\n",
        "        best_idx = np.argmax(fitness_scores)\n",
        "        if fitness_scores[best_idx] > best_fitness:\n",
        "            best_fitness = fitness_scores[best_idx]\n",
        "            best_chromosome = population[best_idx].copy()\n",
        "\n",
        "        # Selection (tournament)\n",
        "        selected = []\n",
        "        for _ in range(n_pop//2):\n",
        "            i1, i2 = random.sample(range(n_pop), 2)\n",
        "            winner = population[i1] if fitness_scores[i1]>fitness_scores[i2] else population[i2]\n",
        "            selected.append(winner)\n",
        "\n",
        "        # Crossover + Mutation\n",
        "        children = []\n",
        "        while len(children) < n_pop:\n",
        "            p1, p2 = random.sample(selected, 2)\n",
        "            point = random.randint(1, n_features-1)\n",
        "            child = np.concatenate([p1[:point], p2[point:]])\n",
        "            # mutation\n",
        "            for i in range(n_features):\n",
        "                if random.random() < mutation_rate:\n",
        "                    child[i] = 1 - child[i]\n",
        "            children.append(child)\n",
        "        population = children\n",
        "        print(f\"GA Generation {gen+1}: Best fitness = {best_fitness:.4f}\")\n",
        "\n",
        "    return best_chromosome.astype(bool)\n",
        "\n",
        "best_chromosome = run_ga_feature_selection(X_train, y_train)\n",
        "\n",
        "# Train logistic regression on GA selected features\n",
        "X_train_ga = X_train[:, best_chromosome]\n",
        "X_test_ga = X_test[:, best_chromosome]\n",
        "model_ga = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_ga.fit(X_train_ga, y_train)\n",
        "y_pred_ga = model_ga.predict(X_test_ga)\n",
        "\n",
        "print_metrics(y_test, y_pred_ga, \"Logistic Regression + GA Feature Selection\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUnFLVFrRHT6",
        "outputId": "04ec921d-b259-4899-8839-5636c5fb909e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GA Generation 1: Best fitness = 0.9485\n",
            "GA Generation 2: Best fitness = 0.9485\n",
            "GA Generation 3: Best fitness = 0.9485\n",
            "GA Generation 4: Best fitness = 0.9485\n",
            "GA Generation 5: Best fitness = 0.9509\n",
            "GA Generation 6: Best fitness = 0.9509\n",
            "GA Generation 7: Best fitness = 0.9509\n",
            "GA Generation 8: Best fitness = 0.9509\n",
            "GA Generation 9: Best fitness = 0.9509\n",
            "GA Generation 10: Best fitness = 0.9509\n",
            "\n",
            "--- Logistic Regression + GA Feature Selection ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       592\n",
            "           1       0.54      0.21      0.30        34\n",
            "\n",
            "    accuracy                           0.95       626\n",
            "   macro avg       0.75      0.60      0.64       626\n",
            "weighted avg       0.93      0.95      0.94       626\n",
            "\n",
            "Accuracy: 0.9473\n",
            "Precision: 0.5385\n",
            "Recall: 0.2059\n",
            "F1 Score: 0.2979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pyswarms as ps\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(X_train, X_test, y_train, y_test):\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test, y_pred, zero_division=0)\n",
        "    }\n",
        "\n",
        "# PSO Fitness Function\n",
        "def pso_fitness(mask):\n",
        "    scores = []\n",
        "    for particle in mask:\n",
        "        selected = np.where(particle == 1)[0]\n",
        "        if len(selected) == 0:\n",
        "            scores.append(0)\n",
        "            continue\n",
        "        X_train_sel = X_train[:, selected]\n",
        "        X_test_sel = X_test[:, selected]\n",
        "        score = evaluate_model(X_train_sel, X_test_sel, y_train, y_test)[\"f1\"]\n",
        "        scores.append(score)\n",
        "    return -np.array(scores)  # PSO minimizes\n",
        "\n",
        "# Run PSO\n",
        "n_features = X_train.shape[1]\n",
        "options = {'c1': 2.0, 'c2': 2.0, 'w': 0.5, 'k': 5, 'p': 2}\n",
        "optimizer = ps.discrete.BinaryPSO(n_particles=60, dimensions=n_features, options=options)\n",
        "\n",
        "cost, pos = optimizer.optimize(pso_fitness, iters=100)\n",
        "\n",
        "# Evaluate Final Model with PSO-selected features\n",
        "selected_pso = np.where(pos == 1)[0]\n",
        "results_pso = evaluate_model(X_train[:, selected_pso], X_test[:, selected_pso], y_train, y_test)\n",
        "\n",
        "# Print PSO Summary\n",
        "print(\"\\n--- PSO Feature Selection Summary ---\")\n",
        "print(f\"Selected Features (indices): {selected_pso}\")\n",
        "print(f\"Accuracy:  {results_pso['accuracy']:.4f}\")\n",
        "print(f\"Precision: {results_pso['precision']:.4f}\")\n",
        "print(f\"Recall:    {results_pso['recall']:.4f}\")\n",
        "print(f\"F1 Score:  {results_pso['f1']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYCW4rAjRZAF",
        "outputId": "a0190c2d-8731-4162-e8a0-595e1115c6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-17 17:44:12,635 - pyswarms.discrete.binary - INFO - Optimize for 100 iters with {'c1': 2.0, 'c2': 2.0, 'w': 0.5, 'k': 5, 'p': 2}\n",
            "pyswarms.discrete.binary: 100%|██████████|100/100, best_cost=-0.458\n",
            "2025-05-17 17:47:45,188 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: -0.4583333333333333, best pos: [1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0\n",
            " 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PSO Feature Selection Summary ---\n",
            "Selected Features (indices): [ 0  2  3  5  7  8  9 11 12 14 16 18 21 24 26 27 29 30 31 32 35 37 42 43\n",
            " 44 51 52 55 58 61 63 65 66 67 71 73]\n",
            "Accuracy:  0.9585\n",
            "Precision: 0.7857\n",
            "Recall:    0.3235\n",
            "F1 Score:  0.4583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Collect results in a dictionary\n",
        "comparison_results = {\n",
        "    \"Model\": [\n",
        "        \"Logistic Regression (All features)\",\n",
        "        \"Logistic Regression + GA Feature Selection\",\n",
        "        \"Logistic Regression + PSO Feature Selection\"\n",
        "    ],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_ml),\n",
        "        accuracy_score(y_test, y_pred_ga),\n",
        "        results_pso['accuracy']\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_ml, zero_division=0),\n",
        "        precision_score(y_test, y_pred_ga, zero_division=0),\n",
        "        results_pso['precision']\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_ml, zero_division=0),\n",
        "        recall_score(y_test, y_pred_ga, zero_division=0),\n",
        "        results_pso['recall']\n",
        "    ],\n",
        "    \"F1 Score\": [\n",
        "        f1_score(y_test, y_pred_ml, zero_division=0),\n",
        "        f1_score(y_test, y_pred_ga, zero_division=0),\n",
        "        results_pso['f1']\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df_comparison = pd.DataFrame(comparison_results)\n",
        "\n",
        "print(\"\\n--- Model Comparison ---\")\n",
        "print(df_comparison)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4zNGq4bTbLd",
        "outputId": "896eae93-2d2e-45aa-afdd-d775fa965977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Comparison ---\n",
            "                                         Model  Accuracy  Precision    Recall  \\\n",
            "0           Logistic Regression (All features)  0.945687   0.500000  0.235294   \n",
            "1   Logistic Regression + GA Feature Selection  0.947284   0.538462  0.205882   \n",
            "2  Logistic Regression + PSO Feature Selection  0.958466   0.785714  0.323529   \n",
            "\n",
            "   F1 Score  \n",
            "0  0.320000  \n",
            "1  0.297872  \n",
            "2  0.458333  \n"
          ]
        }
      ]
    }
  ]
}